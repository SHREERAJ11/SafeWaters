{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZBw4DTILyDcYeeX1/zlxJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SHREERAJ11/SafeWaters/blob/main/Model/Baseline_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtV7Fk4JzzDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa021430-6209-4919-d51c-a16e6f6b26d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "import cv2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "wOD7ScZO8GZp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load JSON files\n",
        "with open('/content/gdrive/MyDrive/FloodNet Challenge @ EARTHVISION 2021 - Track 2/Questions/Training Question.json') as f:\n",
        "    train_questions = json.load(f)\n",
        "with open('/content/gdrive/MyDrive/FloodNet Challenge @ EARTHVISION 2021 - Track 2/Questions/Valid Question.json') as f:\n",
        "    valid_questions = json.load(f)\n",
        "with open('/content/gdrive/MyDrive/FloodNet Challenge @ EARTHVISION 2021 - Track 2/Questions/Test_Question.json') as f:\n",
        "    test_questions = json.load(f)\n",
        "\n",
        "questions = {\n",
        "    'train': train_questions,\n",
        "    'valid': valid_questions,\n",
        "    'test': test_questions\n",
        "}\n",
        "\n",
        "# Define image folders\n",
        "image_folders = {\n",
        "    'train': '/content/gdrive/MyDrive/FloodNet Challenge @ EARTHVISION 2021 - Track 2/Images/Train_Image',\n",
        "    'valid': '/content/gdrive/MyDrive/FloodNet Challenge @ EARTHVISION 2021 - Track 2/Images/Valid_Image',\n",
        "    'test': '/content/gdrive/MyDrive/FloodNet Challenge @ EARTHVISION 2021 - Track 2/Images/Test_Image'\n",
        "}"
      ],
      "metadata": {
        "id": "NvICQSrJ0Fba"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess images\n",
        "def preprocess_images(image_folder, question_data, target_size=(128, 128)):\n",
        "    image_list = []\n",
        "    labels = []\n",
        "    for key, value in question_data.items():\n",
        "        image_id = value['Image_ID']\n",
        "        ground_truth = value.get('Ground_Truth')  # Use .get to handle missing keys\n",
        "        if ground_truth:\n",
        "            image_path = os.path.join(image_folder, image_id)\n",
        "            img = cv2.imread(image_path)\n",
        "            if img is not None:  # Ensure the image is read correctly\n",
        "                img_resized = cv2.resize(img, target_size)  # Resize image\n",
        "                image_list.append(img_resized)\n",
        "                labels.append(ground_truth)\n",
        "    return np.array(image_list), np.array(labels)"
      ],
      "metadata": {
        "id": "IxFx8ev98RJS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess images and labels for training data\n",
        "train_images, train_labels = preprocess_images(image_folders['train'], questions['train'])\n",
        "valid_images, _ = preprocess_images(image_folders['valid'], questions['valid'])\n",
        "test_images, _ = preprocess_images(image_folders['test'], questions['test'])"
      ],
      "metadata": {
        "id": "tWD_TgQK0FX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "train_labels_encoded = to_categorical(train_labels_encoded)"
      ],
      "metadata": {
        "id": "A0hBjTFc0FWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-validation split\n",
        "train_images, val_images, train_labels_encoded, val_labels_encoded = train_test_split(\n",
        "    train_images, train_labels_encoded, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "7-ZiUAbv8DJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print shapes to verify\n",
        "print(f\"Train Images: {train_images.shape}, Train Labels: {train_labels_encoded.shape}\")\n",
        "print(f\"Validation Images: {val_images.shape}, Validation Labels: {val_labels_encoded.shape}\")\n",
        "print(f\"Test Images: {test_images.shape}\")"
      ],
      "metadata": {
        "id": "xC-RjLYL8DGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ],
      "metadata": {
        "id": "emO3NlUA-1nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "Nzve0pU-8DEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "IjmNU-bm8DCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "7Hh2GXjK8C_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_images, train_labels_encoded,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_data=(val_images, val_labels_encoded),\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "id": "dD0lz4pL-_zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('cnn_model.h5')"
      ],
      "metadata": {
        "id": "sHwDrZjj-_pC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "val_loss, val_accuracy = model.evaluate(val_images, val_labels_encoded)\n",
        "print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")"
      ],
      "metadata": {
        "id": "fzA2YwqB-_b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test data\n",
        "test_predictions = model.predict(test_images)\n",
        "test_predicted_labels = np.argmax(test_predictions, axis=1)\n",
        "test_predicted_ground_truth = label_encoder.inverse_transform(test_predicted_labels)"
      ],
      "metadata": {
        "id": "mTb3CB1u_NQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print some predictions\n",
        "for i in range(5):\n",
        "    print(f\"Test Image {i+1}: Predicted Ground Truth: {test_predicted_ground_truth[i]}\")"
      ],
      "metadata": {
        "id": "fp898UhN_NIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8KaOkLAk_URn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}